{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextDL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "amVb-widc6Uv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYV0rUhJlRmg",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://drive.google.com/open?id=1yz04kc2zstt1SlyamzuyWF_4DjPQE0Ta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR_WWQDYijg-",
        "colab_type": "text"
      },
      "source": [
        "# Техническая часть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfdxPRMiWE9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "train_text_dwld = drive.CreateFile({'id':'1I9vf6z80Pjs4oou2WJE728s4HpiFR1qm'})\n",
        "train_text_dwld.GetContentFile('train.ft.txt.bz2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSrw_8fdchlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import bz2\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_Olq2kjdjmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_labels_and_texts(file):\n",
        "    labels = []\n",
        "    texts = []\n",
        "    count = 0\n",
        "    for line in bz2.BZ2File(file):\n",
        "        x = line.decode(\"utf-8\")\n",
        "        if len(x[10:].strip().split(' ')) < 100:\n",
        "            texts.append(x[10:].strip())\n",
        "            labels.append(int(x[9]) - 1)\n",
        "            count +=1\n",
        "\n",
        "        if count > 500000:\n",
        "            return labels, texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHbkP2VAjV8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)\n",
        "    text = re.sub(r'https?:/\\/\\S+', ' ', text)\n",
        "    return text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMNpAgNRdpLs",
        "colab_type": "text"
      },
      "source": [
        "# Что там с данными"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWt_myQWdsWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels, train_texts = get_labels_and_texts('train.ft.txt.bz2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyWLDXSFjO_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts = [preprocess_text(t) for t in train_texts]\n",
        "assert len(train_labels) == len(train_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG_wsRbY1UHi",
        "colab_type": "code",
        "outputId": "0bfdb7cc-7904-4273-9095-c36ca6dae486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "source": [
        "text = [i.split(' ') for i in train_texts]\n",
        "sentence_lengths = [len(tokens) for tokens in text]\n",
        "# порисуем\n",
        "fig = plt.figure(figsize=(10, 10)) \n",
        "plt.xlabel('Длина предложений')\n",
        "plt.ylabel('Кол-во предложений')\n",
        "plt.title('Распределение слов')\n",
        "plt.hist(sentence_lengths)\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAJdCAYAAABQ/VEyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFPvsRyXx5Wb",
        "colab_type": "code",
        "outputId": "989278dc-0a53-4e76-9a4c-735d38007fb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "dt = pd.DataFrame(list(zip(train_labels, train_texts)), columns =['labels', 'texts'])\n",
        "dt.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>stuning even for the non gamer this sound trac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the best soundtrack ever to anything i m readi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>remember pull your jaw off the floor after hea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>whispers of the wicked saints this was a easy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>the worst a complete waste of time typographic...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   labels                                              texts\n",
              "0       1  stuning even for the non gamer this sound trac...\n",
              "1       1  the best soundtrack ever to anything i m readi...\n",
              "2       1  remember pull your jaw off the floor after hea...\n",
              "3       1  whispers of the wicked saints this was a easy ...\n",
              "4       0  the worst a complete waste of time typographic..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju4O8yUS14sL",
        "colab_type": "code",
        "outputId": "bc1f3035-6df4-4a5e-8bd0-29a582251fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "dt['labels'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    260585\n",
              "0    239416\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LQCD93DmDs9",
        "colab_type": "text"
      },
      "source": [
        "Классы сбалансированы, а это значит, можно и accuracy использовать для оценки точности алгоритма. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkiRPBZ9kInX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_texts, train_labels,\n",
        "                                                    test_size=0.3, random_state=40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amVb-widc6Uv",
        "colab_type": "text"
      },
      "source": [
        "# Классика"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gizudYjeE5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIz5-Rm9dNMk",
        "colab_type": "text"
      },
      "source": [
        "## BaseLine: Tf-Idf + LogReg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfB5PklSo4cK",
        "colab_type": "text"
      },
      "source": [
        "### TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvz-rXk9o8o_",
        "colab_type": "text"
      },
      "source": [
        "**TF-IDF** - это term frequency-inverse document frequency или, ежели на великом и могучем, частотность терминов-обратная частотность документов. Ага, лично мне было очень трудно просто принять это название. \n",
        "\n",
        "Если возникает вопрос, зачем он нужен, то ответ прост - компьютер не понимает слова, а понимает только цифры. Надо из слов сделать цифры. Вся идея, это уже потом захотели еще и контекст сохранять, но об этом позже. \n",
        "\n",
        "Вообще, простыми словами это простой и удобный способ оценить важность термина для какого-либо документа относительно всех остальных документов. Принцип такой — если слово встречается в каком-либо документе часто, при этом встречаясь редко во всех остальных документах — это слово имеет большую значимость для того самого документа."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQhDSjpSphiv",
        "colab_type": "text"
      },
      "source": [
        "TF-IDF, как бы глупо не звучало, состоит из TF и IDF, точнее их произведение. А теперь подробнее про каждый элемент:\n",
        "\n",
        "**TF слова а** - (Количество раз, когда слово а встретился в тексте / количество всех слов в тексте)\n",
        "\n",
        "**IDF слова а** - Log(Общее количество документов / Количество документов, в которых встречается слово а) \n",
        "\n",
        "Считается как-нибудь так:\n",
        "$$\\text{idf}(t) = \\text{log}\\frac{1 + n_a}{1 + n_{a(t)}} + 1$$\n",
        "где $n_a$ - число всех документов, а $n_{a(t)}$ - число документов со словом `a`.\n",
        "\n",
        "\n",
        "А потом перемножаем и оп у нас уже есть мера важности слова. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iep7o4xcoRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfidf(data):\n",
        "    tfidf_vectorizer = TfidfVectorizer(analyzer = \"word\")\n",
        "\n",
        "    train = tfidf_vectorizer.fit_transform(data)\n",
        "\n",
        "    return train, tfidf_vectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErKQcvqhkARk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tfidf, tfidf_vectorizer = tfidf(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB6fh4U_kcXl",
        "colab_type": "code",
        "outputId": "4bcfe763-35ec-4a36-d7d6-9faea9a91899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train_tfidf, y_train)\n",
        "pred = lr.predict(X_test_tfidf)\n",
        "\n",
        "print('Результат (f-мера): {}'.format(f1_score(y_test, pred)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Результат (f-мера): 0.9147515547698687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOsIEjIOmoKO",
        "colab_type": "text"
      },
      "source": [
        "А можно так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2C3g5KwmVni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "36a6a9a9-879f-476b-cf52-8eb3ea64c637"
      },
      "source": [
        "vectorizer = TfidfVectorizer(analyzer='word')\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "]) \n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "print('accuracy: ', accuracy_score(y_test, pred))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:  0.9106272624849168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK-BSmx1lNnW",
        "colab_type": "text"
      },
      "source": [
        "## Добавим n-gramm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lklqZ6Kttcuo",
        "colab_type": "text"
      },
      "source": [
        "Разберемся, что такое n-gramm. Например, слово `кружка` мы можем представить в виде такой последовательности триграмм:\n",
        "\n",
        "`##к #кр кру руж ужк жка ка# а##`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvXrCLFTlGsO",
        "colab_type": "code",
        "outputId": "f44e7e0e-33a3-426b-f22b-1e08e8efd605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2))\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "]) \n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "print('accuracy: ', accuracy_score(y_test, pred))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:  0.9278271478190145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU5dkeHKky8v",
        "colab_type": "text"
      },
      "source": [
        "## TODO: W2V + tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iA1qQRfk4Z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4E3sSbMf-jj",
        "colab_type": "text"
      },
      "source": [
        "## Предсказание"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqKfG6OjgECs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def user_predict(text, model=model):\n",
        "    predict = model.predict([text])\n",
        "    predict_pr = model.predict_proba([text])\n",
        "    if predict == 0:\n",
        "        return ('Это негативное высказывания с вероятностью: {:.2f}%'.format(predict_pr[0][0]*100))\n",
        "    if predict == 1:\n",
        "        return ('Это положительное высказывания с вероятностью: {:.2f}%'.format(predict_pr[0][1]*100))\n",
        "    \n",
        "    return predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKjvUSbLgD3q",
        "colab_type": "code",
        "outputId": "abd98f75-ffb7-4a5a-bef1-080d3a6db731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "user_predict('ah shit here we go again')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Это негативное высказывания с вероятностью: 58.04%'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XHI6QzJkUwo",
        "colab_type": "code",
        "outputId": "729fa019-3a4d-4667-dbc6-08584df6ab83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "user_predict('shut up and take my money')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Это негативное высказывания с вероятностью: 90.28%'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qqakn2Hl31y",
        "colab_type": "text"
      },
      "source": [
        "# Диип Лёрнинг"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBYh0NnRBUdZ",
        "colab_type": "text"
      },
      "source": [
        "![хехехе](https://raw.githubusercontent.com/DanilDmitriev1999/Sentiment_Analysis_from-to/master/img/meme.png)\n",
        "\n",
        "Люблю эту картинку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9-bi_1ZfuY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW-SglHlsRAm",
        "colab_type": "code",
        "outputId": "165fae36-b053-4425-ba5d-5915e27dc9fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "if device == 'cpu':\n",
        "    print('cpu')\n",
        "else:\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "is_cuda = torch.cuda.is_available()\n",
        "print(\"Cuda Status on system is {}\".format(is_cuda))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P4\n",
            "Cuda Status on system is True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EzbtbXpyBln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = Counter() \n",
        "for i, sentence in enumerate(text):\n",
        "    text[i] = []\n",
        "    for word in sentence:\n",
        "        words.update([word]) \n",
        "        text[i].append(word)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrTPxMsszBNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Удаление слов, которые появляются меньше 5 раз\n",
        "words = {k:v for k,v in words.items() if v>5}\n",
        "# Сортировка слов по количеству появлений, причем наиболее распространенным словом является первое\n",
        "words = sorted(words, key=words.get, reverse=True)\n",
        "# Добавление PAD-ов\n",
        "words = ['_PAD','_UNK'] + words\n",
        "# Словари для хранения слов в индексных сопоставлениях и наоборот\n",
        "word2idx = {o:i for i,o in enumerate(words)}\n",
        "idx2word = {i:o for i,o in enumerate(words)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQu9H43W2L0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, sentence in enumerate(text):\n",
        "    # Поиск словаря сопоставления и присвоение индекса соответствующим словам\n",
        "    text[i] = [word2idx[word] if word in word2idx else 0 for word in sentence]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7UCxUPX2TZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Определение функции, которая либо сокращает предложения, либо дополняет предложения с 0 до фиксированной длины\n",
        "def pad_input(sentences, seq_len):\n",
        "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
        "    for ii, review in enumerate(sentences):\n",
        "        if len(review) != 0:\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eJL-jvm2rx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len = 200 #Длина, до которой предложения будут дополнены / сокращены\n",
        "\n",
        "train_sentences = pad_input(text, seq_len)\n",
        "train_labels = np.array(train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIfW0YB7222X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_sentences, train_labels,\n",
        "                                                    test_size=0.3, random_state=40)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                    test_size=0.1, random_state=40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KREOd0zM3G_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "val_data = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True, )\n",
        "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "# del X_train, y_train, X_val, y_val, X_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldb7jAnZ3QOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-vWxxL35vwb",
        "colab_type": "code",
        "outputId": "bd895383-c761-4dac-f199-294eff46dc9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print(sample_x.shape, sample_y.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 200]) torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyCZz4S4HrA8",
        "colab_type": "code",
        "outputId": "4553f636-e623-4e01-cac0-3d14e69aa5a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "dataiter_val = iter(val_loader)\n",
        "sample_x, sample_y = dataiter_val.next()\n",
        "\n",
        "print(sample_x.shape, sample_y.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 200]) torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ42WTZcpeSK",
        "colab_type": "text"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OigaQkqMBnux",
        "colab_type": "text"
      },
      "source": [
        "![rnn](https://raw.githubusercontent.com/DanilDmitriev1999/Sentiment_Analysis_from-to/master/img/rnn1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLOpkd0f3qhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.lin = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, text):\n",
        "        batch_size = text.size(0)\n",
        "        text = text.long()\n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "        output = output.contiguous()\n",
        "        \n",
        "        output = self.lin(output)\n",
        "        output = self.sigmoid(output)\n",
        "        \n",
        "        output = output.view(batch_size, -1)\n",
        "        output = output[:,-1]\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6eoxz6i3xyq",
        "colab_type": "code",
        "outputId": "60603201-ce07-4579-dcc9-4ae5fbf0c50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "INPUT_DIM = len(word2idx) + 1\n",
        "EMBEDDING_DIM = 200\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "model"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(51170, 200)\n",
              "  (rnn): RNN(200, 256)\n",
              "  (lin): Linear(in_features=256, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Soeif-4Huo",
        "colab_type": "code",
        "outputId": "9039d52b-1236-4cf3-be4b-a32bd87f8be6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Модель имеет {count_parameters(model):,} параметров')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Модель имеет 10,351,505 параметров\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM96i38k4P9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#model = model.to(device)\n",
        "#criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU4IMHoy4ed5",
        "colab_type": "code",
        "outputId": "dbc14b98-b9fb-4908-8a72-dde740cc1887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        "epochs = 2\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip = 5\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "model.train()\n",
        "for i in range(epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        inputs, labels = inputs, labels\n",
        "        model.zero_grad()\n",
        "        output = model(inputs)\n",
        "        loss = criterion(output, labels.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        if counter%print_every == 0:\n",
        "            val_losses = []\n",
        "            model.eval()\n",
        "            for inp, lab in val_loader:\n",
        "                inp, lab = inp, lab\n",
        "                out = model(inp)\n",
        "                #print(out.shape)\n",
        "                val_loss = criterion(out, lab.float())\n",
        "                val_losses.append(val_loss.item())\n",
        "                \n",
        "            model.train()\n",
        "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2... Step: 100... Loss: 0.707362... Val Loss: 0.693782\n",
            "Epoch: 1/2... Step: 200... Loss: 0.691654... Val Loss: 0.692219\n",
            "Epoch: 1/2... Step: 300... Loss: 0.686343... Val Loss: 0.691815\n",
            "Epoch: 1/2... Step: 400... Loss: 0.679715... Val Loss: 0.693115\n",
            "Epoch: 1/2... Step: 500... Loss: 0.693023... Val Loss: 0.691440\n",
            "Epoch: 1/2... Step: 600... Loss: 0.699584... Val Loss: 0.691679\n",
            "Epoch: 1/2... Step: 700... Loss: 0.704016... Val Loss: 0.692860\n",
            "Epoch: 1/2... Step: 800... Loss: 0.697955... Val Loss: 0.698858\n",
            "Epoch: 1/2... Step: 900... Loss: 0.714311... Val Loss: 0.698148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-8357d5d9696d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-b50050e029df>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 217\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvcczraCvG8t",
        "colab_type": "text"
      },
      "source": [
        "Оч долго обучается, достаточно. Loss стремный"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se8d9OssNgQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_losses = []\n",
        "num_correct = 0\n",
        "\n",
        "model.eval()\n",
        "for inputs, labels in test_loader:\n",
        "    output = model(inputs)\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    pred = torch.round(output.squeeze()) #rounds the output to 0/1\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xU0LESc4A8E",
        "colab_type": "code",
        "outputId": "fae690a9-1464-49d6-f911-b0d09db530fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}%\".format(test_acc*100))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.692\n",
            "Test accuracy: 52.490%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJERkLyezyvd",
        "colab_type": "text"
      },
      "source": [
        "Ну, тут чет не весело: 52% точности. Очень не исключено, что я это я где-то промохнулся, хотя я бы не стал доверять RNN, слишком уж они стремные.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQTwe93PD8al",
        "colab_type": "text"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMKm4Eslzxhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentNet(nn.Module):\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        super(SentimentNet, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers,\n",
        "                            dropout=drop_prob, batch_first=True,\n",
        "                            bidirectional=True)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        batch_size = x.size(0)\n",
        "        x = x.long()\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim*2)\n",
        "        \n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        out = self.sigmoid(out)\n",
        "        \n",
        "        out = out.view(batch_size, -1)\n",
        "        out = out[:,-1]\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(self.n_layers * 2, batch_size, self.hidden_dim).zero_().to(device),\n",
        "                      weight.new(self.n_layers * 2, batch_size, self.hidden_dim).zero_().to(device))\n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtuwvozyFoBI",
        "colab_type": "code",
        "outputId": "1ae1b732-f506-44c1-e9f8-40fa7fdd92aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "vocab_size = len(word2idx) + 1\n",
        "output_size = 1\n",
        "embedding_dim = 200\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "model.to(device)\n",
        "print(model)\n",
        "print(f'Модель имеет {count_parameters(model):,} параметров')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentNet(\n",
            "  (embedding): Embedding(51170, 200)\n",
            "  (lstm): LSTM(200, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "Модель имеет 12,749,457 параметров\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXLuS7icF1v5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr=0.001\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JB95JErF6zm",
        "colab_type": "code",
        "outputId": "0d51578c-dc8f-403e-c0bd-695f057842d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "source": [
        "epochs = 2\n",
        "counter = 0\n",
        "print_every = 500\n",
        "clip = 5\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "model.train()\n",
        "for i in range(epochs):\n",
        "    h = model.init_hidden(batch_size)\n",
        "    \n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        h = tuple([e.data for e in h])\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        model.zero_grad()\n",
        "        output, h = model(inputs, h)\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        if counter%print_every == 0:\n",
        "            val_h = model.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            model.eval()\n",
        "            for inp, lab in val_loader:\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "                inp, lab = inp.to(device), lab.to(device)\n",
        "                out, val_h = model(inp, val_h)\n",
        "                val_loss = criterion(out.squeeze(), lab.float())\n",
        "                val_losses.append(val_loss.item())\n",
        "                \n",
        "            model.train()\n",
        "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2... Step: 500... Loss: 0.266939... Val Loss: 0.319916\n",
            "Epoch: 1/2... Step: 1000... Loss: 0.179538... Val Loss: 0.232975\n",
            "Epoch: 1/2... Step: 1500... Loss: 0.129894... Val Loss: 0.200912\n",
            "Epoch: 1/2... Step: 2000... Loss: 0.152333... Val Loss: 0.187183\n",
            "Epoch: 2/2... Step: 2500... Loss: 0.129379... Val Loss: 0.175909\n",
            "Epoch: 2/2... Step: 3000... Loss: 0.176354... Val Loss: 0.172896\n",
            "Epoch: 2/2... Step: 3500... Loss: 0.163189... Val Loss: 0.173738\n",
            "Epoch: 2/2... Step: 4000... Loss: 0.112212... Val Loss: 0.166080\n",
            "Epoch: 2/2... Step: 4500... Loss: 0.106493... Val Loss: 0.165175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axyd1Wj3GC1n",
        "colab_type": "code",
        "outputId": "28b61cab-08c4-4a61-a7d2-3cc9a6495752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "test_losses = []\n",
        "num_correct = 0\n",
        "h = model.init_hidden(batch_size)\n",
        "\n",
        "model.eval()\n",
        "for inputs, labels in test_loader:\n",
        "    h = tuple([each.data for each in h])\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    output, h = model(inputs, h)\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    pred = torch.round(output.squeeze()) #rounds the output to 0/1\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "        \n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}%\".format(test_acc*100))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.166\n",
            "Test accuracy: 93.392%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu4rv7vfzHjS",
        "colab_type": "text"
      },
      "source": [
        "Уже лучше"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJjsj_oU6OQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}